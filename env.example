PORT=8787
# One or many (comma-separated):
# CLIENT_ORIGIN=https://dashboard.rapidcallai.com,http://localhost:5173
CLIENT_ORIGIN=http://localhost:5173

# LiveKit Cloud project credentials
LIVEKIT_URL=
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=

# --- Twilio inbound -> LiveKit SIP bridge (Phase 3) ---
# Twilio will call our webhook, and we respond with TwiML <Dial><Sip>... to connect into LiveKit.
# LiveKit SIP endpoint (from LiveKit Cloud Project settings), example:
# vjnxecm0tjk.sip.livekit.cloud
# Ref: https://docs.livekit.io/telephony/accepting-calls/inbound-twilio/
LIVEKIT_SIP_ENDPOINT=

# Shared secret for your LiveKit Agent to call internal endpoints (create/end calls, post metrics).
# Choose a strong random string and set the same value in python-agent env as AGENT_SHARED_SECRET.
AGENT_SHARED_SECRET=thisisstrongsecret

# --- Dashboard Voice Configuration previews (optional) ---
# Used by `POST /api/tts/preview` so the browser can play a voice sample without exposing keys client-side.
ELEVENLABS_API_KEY=
CARTESIA_API_KEY=

# --- AI prompt generation (Generate wizard) ---
OPENAI_API_KEY=
# You can change this to any supported OpenAI chat model you have access to.
OPENAI_GENERATE_MODEL=gpt-4.1-mini

# Used to mint short-lived, token-gated recording playback URLs for the browser (so <audio> can stream without Authorization headers).
# If unset, we fall back to AGENT_SHARED_SECRET.
RECORDING_PLAYBACK_SECRET=

# Optional: override the public base URL used when generating absolute playback URLs.
# Example: https://api.rapidcallai.com
PUBLIC_API_BASE_URL=https://api.rapidcallai.com

# --- Twilio (Phase 2: subaccount-per-workspace) ---
# Use your Twilio *master* account credentials. We'll create/manage subaccounts per workspace.
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=

# PostgreSQL (RDS)
# Example:
# DATABASE_URL=postgresql://postgres:password@rapidcallai-database.xxxxx.eu-central-1.rds.amazonaws.com:5432/rapidcallai
DATABASE_URL=
# RDS typically requires SSL; we default to SSL enabled.
# Set to "false" only if you're connecting to a local Postgres without SSL.
DATABASE_SSL=true

# --- LiveKit Egress -> S3 (required to enable recordings) ---
# Egress will upload a single audio-only MP3 to: s3://EGRESS_S3_BUCKET/calls/<callId>.mp3
EGRESS_S3_BUCKET=
EGRESS_S3_REGION=
EGRESS_S3_ACCESS_KEY=
EGRESS_S3_SECRET=
# Optional (for S3-compatible storage like MinIO)
EGRESS_S3_ENDPOINT=
EGRESS_S3_FORCE_PATH_STYLE=false

# --- Optional pricing for cost estimation (if unset, cost will show as â€”) ---
# LLM cost is estimated from UsageCollector's prompt/completion token counts.
# Set these using your providers' official pricing docs (prices change; we intentionally keep rates configurable).
# Example docs:
# - OpenAI pricing: https://platform.openai.com/pricing
# - Deepgram pricing: https://deepgram.com/pricing
# - ElevenLabs pricing: https://elevenlabs.io/pricing
# - Cartesia pricing: https://cartesia.ai/pricing
# Optional: per-model pricing catalog (recommended if customers can pick different LLMs per agent).
# Format (per-1M example):
# LLM_PRICING_JSON={"gpt-5.2":{"inputPer1M":1.75,"cachedInputPer1M":0.175,"outputPer1M":14.0},"gpt-5.1":{"inputPer1M":1.25,"cachedInputPer1M":0.125,"outputPer1M":10.0},"gpt-5":{"inputPer1M":1.25,"cachedInputPer1M":0.125,"outputPer1M":10.0},"gpt-5-mini":{"inputPer1M":0.25,"cachedInputPer1M":0.025,"outputPer1M":2.0},"gpt-5-nano":{"inputPer1M":0.05,"cachedInputPer1M":0.005,"outputPer1M":0.4},"gpt-4.1":{"inputPer1M":2.0,"cachedInputPer1M":0.5,"outputPer1M":8.0},"gpt-4.1-mini":{"inputPer1M":0.4,"cachedInputPer1M":0.1,"outputPer1M":1.6},"gpt-4o":{"inputPer1M":2.5,"cachedInputPer1M":1.25,"outputPer1M":10.0},"gpt-4o-mini":{"inputPer1M":0.15,"cachedInputPer1M":0.075,"outputPer1M":0.6}}
# Format (per-1K example):
# LLM_PRICING_JSON={"gpt-5.2":{"inputPer1K":0.00175,"cachedInputPer1K":0.000175,"outputPer1K":0.014},"gpt-5.1":{"inputPer1K":0.00125,"cachedInputPer1K":0.000125,"outputPer1K":0.01},"gpt-5":{"inputPer1K":0.00125,"cachedInputPer1K":0.000125,"outputPer1K":0.01},"gpt-5-mini":{"inputPer1K":0.00025,"cachedInputPer1K":0.000025,"outputPer1K":0.002},"gpt-5-nano":{"inputPer1K":0.00005,"cachedInputPer1K":0.000005,"outputPer1K":0.0004},"gpt-4.1":{"inputPer1K":0.002,"cachedInputPer1K":0.0005,"outputPer1K":0.008},"gpt-4.1-mini":{"inputPer1K":0.0004,"cachedInputPer1K":0.0001,"outputPer1K":0.0016},"gpt-4o":{"inputPer1K":0.0025,"cachedInputPer1K":0.00125,"outputPer1K":0.01},"gpt-4o-mini":{"inputPer1K":0.00015,"cachedInputPer1K":0.000075,"outputPer1K":0.0006}}
LLM_PRICING_JSON=
LLM_INPUT_USD_PER_1K=
# If your model supports it (and your usage collector reports it), cached input tokens can be billed differently.
LLM_CACHED_INPUT_USD_PER_1K=
LLM_OUTPUT_USD_PER_1K=
# STT cost is estimated from stt_audio_duration seconds.
STT_USD_PER_MIN=
# Optional: STT pricing catalog (per model/backend). Key should match what the agent reports (e.g. "deepgram/nova-3", "livekit/auto").
# STT_PRICING_JSON={"deepgram/nova-3":{"usdPerMin":0.0049}}
STT_PRICING_JSON=
# TTS cost is estimated from tts_characters_count.
TTS_USD_PER_1K_CHARS=
# Optional: TTS pricing catalog (per provider/model). Key should match what the agent reports (e.g. "cartesia/sonic-2", "elevenlabs/eleven_turbo_v2_5").
# TTS_PRICING_JSON={"cartesia/sonic-2":{"usdPer1KChars":0.00030},"elevenlabs/eleven_turbo_v2_5":{"usdPer1KChars":0.00030}}
TTS_PRICING_JSON=

# --- Retail pricing / margin (customer-facing charges) ---
# We compute internal provider costs (COGS) from the catalogs above, then apply this multiplier to get what customers pay.
# Example:
# RETAIL_MARKUP_MULTIPLIER=3   -> customer pays ~3x provider cost
RETAIL_MARKUP_MULTIPLIER=1


